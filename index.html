<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Portafolio IA de Nicolas Mazzey">
    <title>Portafolio de Nicolas Mazzey</title>
    <link rel="stylesheet" href="index.css">
</head>

<body>

<header>
    <h1>¡Bienvenido a mi Portafolio de Machine Learning!</h1>
    <p>Nicolas Mazzey - Desarrollador de Software</p>
</header>

<nav>
    <a href="index.html">Blog</a>
    <a href="proyectos.html">Proyectos</a>
    <a href="tecnologias.html">Tecnologías</a>
</nav>

<section>
    <h2>Introducción</h2>
    <p>Soy Nicolas Mazzey, estudiante de ingeniería en computación de la Universidad Católica. En este portafolio encontrarás información acerca de mis conocimientos, tecnologías, y proyectos de Machine Learning desarrollados a lo largo del curso de Introducción a los métodos de aprendizaje automático de la Universidad Católica del Uruguay.</p>
</section>

<section>
    <h2>Proceso de Machine Learning</h2>
    <p>El proceso de Machine Learning involucra varias factores para construir modelos predictivos eficaces:</p>

    <p><b>Datos de uno o mas datasets:</b> Sin datos los modelos de Machine Learning no se pueden entrenar ni usar. Para ello hacen faltan una cantidad significativa de datos y sobretodo datos que representen adecuadamente la realidad del problema.</p>
    <p>Si un modelo se entrena con datos que no representen la realidad entonces el modelo va predecir de manera incorrecta y generar perdidas a los que confien en el modelo.</p>

    <p><b>Algoritmo de Machine Learning:</b> Es el corazon del proceso de Machine Learning, este algoritmo va a ser el que vamos a entrenar con datos para que pueda clasificar o predecir la variable objetivo en funcion de las caracteristicas del dataset.</p>
    <p>Hay muchisimos algoritmos que pueden funcionar para una situacion dada pero una correcta eleccion marca la diferencia entre un modelo eficaz y otro deficiente.</p>

    <p><b>Error de Test vs Error de Entrenamiento:</b> Cuando se entrena un algoritmo de machine learning nunca hay que usar la misma data con la que se entreno para realizar los test ya que esto ocaciona que el algoritmo tenga siempre un 100% de efectivad y no represente correctamente la realidad donde los datos no van a ser siempre los mismos.</p>
    <p>Para evitar este error lo que se debe hacer es tener un dataset de entrenamiento y un dataset de test, en caso de tener solo un dataset para ambos se puede fraccionar en 2 dataset con un particion 70% para entrenamiento y 30% para test. </p>

    <p><b>Variable Objetivo:</b> En los problemas de Machine Learning lo mas importante es ubicar que parametro del dataset estamos tratando de predecir o clasificar en un problema. 
        Sin esta variable objetivo no hay punto en aplicar un algoritmo de machine Learnning ya que es el objetivos de estos algoritmos y los problemas de Machine Learning en general.</p>
    <p>Por ejemplo si tenemos un dataset de personas cancer de pulmon la variable objetivo a predecir es si la persona tiene cancer del pulmon o no en funcion a sus caracteristicas.</p>
</section>

<section>
    <h2>Tareas de Preparación de Datos</h2>
    <p>La preparación de los datos es uno de los pasos más importantes en Machine Learning. Entre las tareas que realizo están:</p>
    <p><b>Análisis de Distribuciones:</b> En la preparacion de datos es importante ver que distribuciones tiene cada caracteristica debido a que hay algoritmos que asumen que las caracteristicas se comportan de cierta manera por ejemplo que sigan un distribucion gaussiana para usar naive bayes.</p>
    <p><b>Detección y manejo de <i>Outliers</i>:</b> Es relevante quitar los outliers porque si son muy atipicos pueden afectar el rendimiento del modelo ya que son valores muy inusuales y que no deberian de ser considerados en la realidad.</p>
    <p><b>Imputación de valores faltantes:</b> Los valores faltantes afectan negativamente al modelo ya que son tuplas que no aportan informacion para la caracteristica y aumentan el costo computacional es mejor removerlos o remplazarlos para mejorar el modelo.</p>
    <p><b>Normalización de características:</b> Es el proceso de escalar los datos a un rango estándar, necesario para algoritmos que dependen de la magnitud de las características, como KNN.</p>
</section>

<section id="AlgoritmosLineales">
    <h2>Algoritmos Lineales</h2>
    <p>En Machine Learning, los algoritmos lineales son fundamentales para modelar relaciones entre variables. Entre los que he utilizado están:</p>
    <ul>
        <li><b>Descenso de Gradiente:</b> Método iterativo de optimización para encontrar los valores de los parámetros que minimizan una función de coste. Se utiliza comúnmente en regresión lineal y redes neuronales.</li>
        <li><b>Regresión Lineal:</b> Técnica utilizada para predecir una variable continua en función de una o más variables independientes. Busca ajustar una línea que minimice el error cuadrático medio.</li>
        <li><b>Regresión Logística:</b> Modelo estadístico utilizado para problemas de clasificación binaria, que estima la probabilidad de que un evento ocurra (como sí/no, 1/0).</li>
        <li><b>Análisis Discriminante Lineal (LDA):</b> Técnica supervisada utilizada para clasificación que proyecta los datos en un espacio de menor dimensionalidad maximizando la separación entre clases.</li>
    </ul>
    <h4>Principales Ventajas:</h4>
    <ul>
        <li>Simplicidad: Los modelos lineales son matemáticamente simples, lo que los hace fáciles de entender e interpretar.</li>
        <li>Velocidad: Son muy rápidos en términos de entrenamiento y predicción, lo cual es ideal para trabajar con grandes conjuntos de datos.</li>
        <li>Interpretabilidad: Los algoritmos lineales son altamente interpretables, lo cual permite entender mejor los pesos que tiene cada caracteristica permitiendo mejorar el modelo con facilidad.</li>
    </ul>
    <h4>Aplicaciones:</h4>
    <a href="proyectos.html#proyecto_Regresión_Logistica">Proyecto de Regresión Logistica para predecir un 2do ataque cardiaco</a>
</section>

<section id="Naive_Bayes">
    <h2>Naive Bayes</h2>
    <p>El algoritmo de Naive Bayes es un clasificador probabilístico basado en el teorema de Bayes. Asume que todas las características son independientes entre sí dado el valor de la clase objetivo, lo que simplifica enormemente el cálculo de probabilidades.</p>
    <img src="imagenes/Teorema_de_Bayes.jpg" width= 300px height= auto>
    <h4>Principales Ventajas:</h4>
    <ul>
        <li>Es eficiente y rápido, especialmente útil con conjuntos de datos grandes.</li>
        <li>Funciona bien incluso con un número limitado de datos de entrenamiento.</li>
        <li>Requiere menos datos de entrenamiento en comparación con otros clasificadores.</li>
    </ul>
    <h4>Condiciones de Uso:</h4>
    <ul>
        <li>Asume que las características son independientes entre sí.</li>
        <li>Funciona mejor cuando las características siguen una distribución normal.</li>
        <li>Necesita suficientes datos para estimar correctamente las probabilidades.</li>
    </ul>
    <h4>Aplicaciones:</h4>
    <p>Se utiliza en aplicaciones como la clasificación de correos electrónicos (spam/no spam), el análisis de sentimientos, y la categorización de textos.</p>
    <a href="proyectos.html#proyecto_Naibe_Bayes">Proyecto de Naibe Bayes para predecir condiciones para jugar al Golf</a>
</section>

<section id="KNN">
    <h2>K Vecinos más Cercanos (KNN)</h2>
    <p>El algoritmo K-Nearest Neighbors (KNN) es un método de clasificación basado en la proximidad de los datos. Para predecir la clase de un nuevo dato, el algoritmo busca los <i>k</i> ejemplos más cercanos en el espacio de características y asigna la clase más frecuente entre ellos.</p>
    <h4>Ventajas:</h4>
    <ul>
        <li>No hace ninguna suposición sobre la distribución de los datos.</li>
        <li>Es sencillo de entender e implementar.</li>
    </ul>
    <h4>Desventajas:</h4>
    <ul>
        <li>El rendimiento puede verse afectado por el ruido en los datos.</li>
        <li>Requiere un alto coste computacional, ya que se calcula la distancia de cada nuevo dato con todos los datos de entrenamiento.</li>
    </ul>
    <h4>Aplicaciones:</h4>
    <p>Utilizado en problemas de clasificación, como el reconocimiento de patrones y la clasificación de imágenes.</p>
    <a href="proyectos.html#proyecto_KNN">Proyecto de KNN para predecir deporte primario de un deportista</a>
</section>

<section id="SelecciónCaracterísticas">
    <h2>Selección de Características</h2>
    <p>La selección de características es un paso clave en Machine Learning, ya que permite reducir la dimensionalidad del conjunto de datos, mejorando la eficiencia y el rendimiento de los modelos. Los métodos principales incluyen:</p>
    <ul>
        <li><b>Selección Hacia Adelante:</b> Empieza con un conjunto vacío de características y va añadiendo una a una las que mejoran el rendimiento del modelo.</li>
        <li><b>Selección Hacia Atrás:</b> Comienza con todas las características y va eliminando aquellas que menos contribuyen al rendimiento.</li>
        <li><b>Algoritmo Genético:</b> Método basado en la selección natural, donde las mejores combinaciones de características "sobreviven" y se cruzan para crear nuevas soluciones.</li>
    </ul>
    <h4>Aplicaciones:</h4>
    <a href="proyectos.html#proyecto_Seleccion_Característica">Proyecto de comparación entre los 3 tipos de seleccion de caracteristicas</a>

</section>

<footer>
    <p>Puedes contactarme a través de mi <a href="mailto:nicolasmazzey@gmail.com">correo electrónico</a> o seguirme en <a href="https://www.linkedin.com/in/nicolasmazzey">LinkedIn</a>.</p>
    <p>&copy; 2024 Nicolas Mazzey. Todos los derechos reservados.</p>
</footer>

</body>
</html>
